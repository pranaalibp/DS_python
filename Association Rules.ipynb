{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6eb650a",
   "metadata": {},
   "source": [
    "# ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b6524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cd7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "261d2578",
   "metadata": {},
   "source": [
    "#### Association Rule Mining:\n",
    "\n",
    "• Implement an Apriori algorithm using tool like python with libraries such as Pandas and Mlxtend etc.\n",
    "\n",
    "\n",
    "• Apply association rule mining techniques to the pre-processed dataset to discover interesting relationships between products purchased together.\n",
    "\n",
    "\n",
    "\n",
    "• Set appropriate threshold for support, confidence and lift to extract meaning full rules.\n",
    "\n",
    "\n",
    "#### Analysis and Interpretation :\n",
    "\n",
    "\n",
    "\n",
    "• Analyse the generated rules to identify interesting patterns and relationships between the products.\n",
    "\n",
    "\n",
    "\n",
    "• Interpret the results and provide insights into customer purchasing behaviour based on the discovered rules.\n",
    "\n",
    "\n",
    "\n",
    " #### Insights into Customer (Passenger) Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad558ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebf7e8e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\prana\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: mlxtend in c:\\users\\prana\\anaconda3\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055ded46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "data = pd.read_csv(\"Titanic_train.csv\")\n",
    "\n",
    "# Display the column names\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9079a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb8641aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea66222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name_Abbing, Mr. Anthony</th>\n",
       "      <th>Name_Abbott, Mr. Rossmore Edward</th>\n",
       "      <th>Name_Abbott, Mrs. Stanton (Rosa Hunt)</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_F G73</th>\n",
       "      <th>Cabin_F2</th>\n",
       "      <th>Cabin_F33</th>\n",
       "      <th>Cabin_F38</th>\n",
       "      <th>Cabin_F4</th>\n",
       "      <th>Cabin_G6</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  \\\n",
       "0            1         0       3  22.0      1      0   7.2500   \n",
       "1            2         1       1  38.0      1      0  71.2833   \n",
       "2            3         1       3  26.0      0      0   7.9250   \n",
       "3            4         1       1  35.0      1      0  53.1000   \n",
       "4            5         0       3  35.0      0      0   8.0500   \n",
       "\n",
       "   Name_Abbing, Mr. Anthony  Name_Abbott, Mr. Rossmore Edward  \\\n",
       "0                         0                                 0   \n",
       "1                         0                                 0   \n",
       "2                         0                                 0   \n",
       "3                         0                                 0   \n",
       "4                         0                                 0   \n",
       "\n",
       "   Name_Abbott, Mrs. Stanton (Rosa Hunt)  ...  Cabin_F G73  Cabin_F2  \\\n",
       "0                                      0  ...            0         0   \n",
       "1                                      0  ...            0         0   \n",
       "2                                      0  ...            0         0   \n",
       "3                                      0  ...            0         0   \n",
       "4                                      0  ...            0         0   \n",
       "\n",
       "   Cabin_F33  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  Embarked_C  Embarked_Q  \\\n",
       "0          0          0         0         0        0           0           0   \n",
       "1          0          0         0         0        0           1           0   \n",
       "2          0          0         0         0        0           0           0   \n",
       "3          0          0         0         0        0           0           0   \n",
       "4          0          0         0         0        0           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "\n",
       "[5 rows x 1731 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.get_dummies(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e97892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Handle missing values\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02596a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to strings\n",
    "data['Pclass'] = data['Pclass'].astype(str)\n",
    "data['Survived'] = data['Survived'].astype(str)\n",
    "data['SibSp'] = data['SibSp'].astype(str)\n",
    "data['Parch'] = data['Parch'].astype(str)\n",
    "data['Sex'] = data['Sex'].astype(str)\n",
    "data['Embarked'] = data['Embarked'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bce92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of transactions\n",
    "transactions = data.apply(lambda row: list(row.dropna().astype(str)), axis=1).tolist()\n",
    "\n",
    "# For demonstration, convert this into a DataFrame suitable for association rule mining\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "587a6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of transactions\n",
    "transactions = data.apply(lambda row: list(row.dropna().astype(str)), axis=1).tolist()\n",
    "\n",
    "# For demonstration, convert this into a DataFrame suitable for association rule mining\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f15720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           antecedents          consequents  antecedent support  \\\n",
      "0                  (0)  (29.69911764705882)            0.930415   \n",
      "1  (29.69911764705882)                  (0)            0.198653   \n",
      "2                  (0)                  (3)            0.930415   \n",
      "3                  (3)                  (0)            0.557800   \n",
      "4                  (0)               (male)            0.930415   \n",
      "\n",
      "   consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "0            0.198653  0.195286    0.209891  1.056572  0.010456    1.014224   \n",
      "1            0.930415  0.195286    0.983051  1.056572  0.010456    4.105499   \n",
      "2            0.557800  0.531987    0.571773  1.025050  0.013001    1.032630   \n",
      "3            0.930415  0.531987    0.953722  1.025050  0.013001    1.503635   \n",
      "4            0.647587  0.625140    0.671894  1.037535  0.022615    1.074082   \n",
      "\n",
      "   zhangs_metric  \n",
      "0       0.769466  \n",
      "1       0.066816  \n",
      "2       0.351198  \n",
      "3       0.055265  \n",
      "4       0.519893  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Apply the apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the rules\n",
    "print(rules.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af785699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      antecedents consequents  antecedent support  \\\n",
      "46         (29.69911764705882, S)         (0)            0.101010   \n",
      "50      (male, 29.69911764705882)         (0)            0.139169   \n",
      "1             (29.69911764705882)         (0)            0.198653   \n",
      "155                  (male, 3, S)         (0)            0.298541   \n",
      "141  (male, 29.69911764705882, 3)         (0)            0.105499   \n",
      "42         (29.69911764705882, 3)         (0)            0.152637   \n",
      "60                      (male, 3)         (0)            0.390572   \n",
      "5                          (male)         (0)            0.647587   \n",
      "68                      (male, S)         (0)            0.494949   \n",
      "64                      (male, C)         (0)            0.106622   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "46             0.930415  0.101010    1.000000  1.074789  0.007029         inf   \n",
      "50             0.930415  0.136925    0.983871  1.057454  0.007439    4.314254   \n",
      "1              0.930415  0.195286    0.983051  1.056572  0.010456    4.105499   \n",
      "155            0.930415  0.292929    0.981203  1.054586  0.015162    3.701908   \n",
      "141            0.930415  0.103255    0.978723  1.051921  0.005096    3.270483   \n",
      "42             0.930415  0.149270    0.977941  1.051080  0.007254    3.154508   \n",
      "60             0.930415  0.381594    0.977011  1.050081  0.018199    3.026936   \n",
      "5              0.930415  0.625140    0.965338  1.037535  0.022615    2.007520   \n",
      "68             0.930415  0.476992    0.963719  1.035794  0.016484    1.917929   \n",
      "64             0.930415  0.102132    0.957895  1.029535  0.002930    1.652637   \n",
      "\n",
      "     zhangs_metric  \n",
      "46        0.077403  \n",
      "50        0.063116  \n",
      "1         0.066816  \n",
      "155       0.073790  \n",
      "141       0.055180  \n",
      "42        0.057352  \n",
      "60        0.078258  \n",
      "5         0.102654  \n",
      "68        0.068424  \n",
      "64        0.032111  \n"
     ]
    }
   ],
   "source": [
    "# Sort rules by confidence\n",
    "rules = rules.sort_values(by='confidence', ascending=False)\n",
    "\n",
    "# Display top rules\n",
    "print(rules.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2678c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Titanic_train.csv\")\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "data = data.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Handle missing values\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "\n",
    "# Convert categorical variables to strings\n",
    "data['Pclass'] = data['Pclass'].astype(str)\n",
    "data['Survived'] = data['Survived'].astype(str)\n",
    "data['SibSp'] = data['SibSp'].astype(str)\n",
    "data['Parch'] = data['Parch'].astype(str)\n",
    "data['Sex'] = data['Sex'].astype(str)\n",
    "data['Embarked'] = data['Embarked'].astype(str)\n",
    "\n",
    "# Create a list of transactions\n",
    "transactions = data.apply(lambda row: list(row.dropna().astype(str)), axis=1).tolist()\n",
    "\n",
    "# For demonstration, convert this into a DataFrame suitable for association rule mining\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "705ba7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      antecedents consequents  antecedent support  \\\n",
      "46         (29.69911764705882, S)         (0)            0.101010   \n",
      "50      (male, 29.69911764705882)         (0)            0.139169   \n",
      "1             (29.69911764705882)         (0)            0.198653   \n",
      "155                  (male, 3, S)         (0)            0.298541   \n",
      "141  (male, 29.69911764705882, 3)         (0)            0.105499   \n",
      "42         (29.69911764705882, 3)         (0)            0.152637   \n",
      "60                      (male, 3)         (0)            0.390572   \n",
      "5                          (male)         (0)            0.647587   \n",
      "68                      (male, S)         (0)            0.494949   \n",
      "64                      (male, C)         (0)            0.106622   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "46             0.930415  0.101010    1.000000  1.074789  0.007029         inf   \n",
      "50             0.930415  0.136925    0.983871  1.057454  0.007439    4.314254   \n",
      "1              0.930415  0.195286    0.983051  1.056572  0.010456    4.105499   \n",
      "155            0.930415  0.292929    0.981203  1.054586  0.015162    3.701908   \n",
      "141            0.930415  0.103255    0.978723  1.051921  0.005096    3.270483   \n",
      "42             0.930415  0.149270    0.977941  1.051080  0.007254    3.154508   \n",
      "60             0.930415  0.381594    0.977011  1.050081  0.018199    3.026936   \n",
      "5              0.930415  0.625140    0.965338  1.037535  0.022615    2.007520   \n",
      "68             0.930415  0.476992    0.963719  1.035794  0.016484    1.917929   \n",
      "64             0.930415  0.102132    0.957895  1.029535  0.002930    1.652637   \n",
      "\n",
      "     zhangs_metric  \n",
      "46        0.077403  \n",
      "50        0.063116  \n",
      "1         0.066816  \n",
      "155       0.073790  \n",
      "141       0.055180  \n",
      "42        0.057352  \n",
      "60        0.078258  \n",
      "5         0.102654  \n",
      "68        0.068424  \n",
      "64        0.032111  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Apply the apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the rules\n",
    "rules_sorted = rules.sort_values(by='confidence', ascending=False)\n",
    "print(rules_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea907a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7314e60",
   "metadata": {},
   "source": [
    " #### Insights into Customer (Passenger) Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c0c00",
   "metadata": {},
   "source": [
    "Gender and Survival: Female passengers had a significantly higher likelihood of survival. This pattern aligns with the historical context of the \"women and children first\" policy during the Titanic disaster.\n",
    "\n",
    "\n",
    "Class and Survival: First-class passengers were more likely to survive. This indicates a disparity in survival chances based on ticket class, reflecting the socioeconomic differences and possibly the physical location and accessibility of lifeboats.\n",
    "\n",
    "\n",
    "Specific Group Behavior: Female passengers in first class and passengers who embarked from port C in first class had the highest survival rates. This suggests that certain groups had a significant advantage in survival, which could be due to various factors like cabin location, social status, and access to lifeboats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade0124",
   "metadata": {},
   "source": [
    "#### Conclusion -\n",
    "\n",
    "The analysis of the Titanic dataset using association rule mining has uncovered strong associations between survival and factors such as gender, class, and port of embarkation. These insights highlight historical and social dynamics that influenced survival chances during the Titanic disaster. While the dataset is not ideally suited for traditional market basket analysis, the approach demonstrates the versatility of association rule mining in uncovering patterns and relationships within various types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48983255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
